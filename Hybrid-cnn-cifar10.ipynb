{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid CNN + Quantum Neural Network for CIFAR-10\n",
    "Implements a density QNN architecture based on the paper's framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pennylane as qml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Load AWS configuration from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current AWS Configuration:\n",
      "Region: us-east-1\n",
      "Access Key ID: AKIA************ZMTY\n",
      "Secret Access Key: RXLx********************************i0yI\n",
      "Braket Device: arn:aws:braket:::device/quantum-simulator/amazon/sv1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Function to safely get and mask sensitive environment variables\n",
    "def get_masked_env(var_name):\n",
    "    value = os.getenv(var_name, '')\n",
    "    if value and var_name in ['AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY']:\n",
    "        return value[:4] + '*' * (len(value) - 8) + value[-4:]\n",
    "    return value\n",
    "\n",
    "# Display current configuration\n",
    "print(\"Current AWS Configuration:\")\n",
    "print(f\"Region: {get_masked_env('AWS_DEFAULT_REGION')}\")\n",
    "print(f\"Access Key ID: {get_masked_env('AWS_ACCESS_KEY_ID')}\")\n",
    "print(f\"Secret Access Key: {get_masked_env('AWS_SECRET_ACCESS_KEY')}\")\n",
    "print(f\"Braket Device: {get_masked_env('BRAKET_DEVICE')}\")\n",
    "\n",
    "# Function to update AWS configuration\n",
    "def update_aws_config(region=None, access_key=None, secret_key=None, device_arn=None):\n",
    "    if region:\n",
    "        os.environ['AWS_DEFAULT_REGION'] = region\n",
    "    if access_key:\n",
    "        os.environ['AWS_ACCESS_KEY_ID'] = access_key\n",
    "    if secret_key:\n",
    "        os.environ['AWS_SECRET_ACCESS_KEY'] = secret_key\n",
    "    if device_arn:\n",
    "        os.environ['BRAKET_DEVICE'] = device_arn\n",
    "    \n",
    "    clear_output()\n",
    "    print(\"Updated AWS Configuration:\")\n",
    "    print(f\"Region: {get_masked_env('AWS_DEFAULT_REGION')}\")\n",
    "    print(f\"Access Key ID: {get_masked_env('AWS_ACCESS_KEY_ID')}\")\n",
    "    print(f\"Secret Access Key: {get_masked_env('AWS_SECRET_ACCESS_KEY')}\")\n",
    "    print(f\"Braket Device: {get_masked_env('BRAKET_DEVICE')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Loaded batch: torch.Size([4, 3, 32, 32])\n",
      "Loaded batch: torch.Size([4, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 sample\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "print(f\"Loaded batch: {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon Braket SV1 simulator device\n",
    "dev = qml.device(\n",
    "    \"braket.aws.qubit\",\n",
    "    device_arn=os.getenv('BRAKET_DEVICE'),\n",
    "    wires=4,\n",
    "    shots=100  # Set number of shots here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density QNN: Sub-unitary quantum circuit (RBS-based)\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def quantum_sub_circuit(inputs, weights):\n",
    "    # Data encoding\n",
    "    for i in range(4):\n",
    "        qml.RY(inputs[i], wires=i)\n",
    "    \n",
    "    # Parameterized RBS-inspired gates\n",
    "    for i in range(4):\n",
    "        qml.RZ(weights[i], wires=i)\n",
    "    \n",
    "    # Entanglement (CNOT ladder)\n",
    "    for i in range(3):\n",
    "        qml.CNOT(wires=[i, i+1])\n",
    "    \n",
    "    # Second rotation layer\n",
    "    for i in range(4):\n",
    "        qml.RY(weights[i+4], wires=i)\n",
    "    \n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid CNN + Density Quantum Model\n",
    "class HybridDensityQNN(nn.Module):\n",
    "    def __init__(self, num_sub_unitaries=2):\n",
    "        super(HybridDensityQNN, self).__init__()\n",
    "        \n",
    "        # CNN feature extractor\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 4)\n",
    "        \n",
    "        # Density QNN: K sub-unitaries with independent parameters\n",
    "        self.K = num_sub_unitaries\n",
    "        self.quantum_layers = nn.ModuleList([\n",
    "            qml.qnn.TorchLayer(quantum_sub_circuit, {\"weights\": (8,)})\n",
    "            for _ in range(self.K)\n",
    "        ])\n",
    "        \n",
    "        # Trainable mixing coefficients α_k (ensure sum to 1 via softmax)\n",
    "        self.alpha = nn.Parameter(torch.ones(self.K))\n",
    "        \n",
    "        # Final classifier\n",
    "        self.fc2 = nn.Linear(4, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        \n",
    "        # Density QNN: weighted sum of sub-unitaries\n",
    "        alpha_norm = torch.softmax(self.alpha, dim=0)\n",
    "        quantum_out = sum(alpha_norm[k] * self.quantum_layers[k](x) for k in range(self.K))\n",
    "        \n",
    "        # Classification\n",
    "        out = self.fc2(quantum_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 3, 32, 32])\n",
      "Output shape: torch.Size([4, 10])\n",
      "Mixing coefficients α: tensor([0.5000, 0.5000])\n",
      "\n",
      "Output logits:\n",
      "tensor([[ 0.2526, -0.3160,  0.0282,  0.6928,  0.0157, -0.7796, -0.5577,  0.0707,\n",
      "          0.1227, -0.4648],\n",
      "        [ 0.2553, -0.3378,  0.0234,  0.6888,  0.0476, -0.7318, -0.5319,  0.0629,\n",
      "          0.0822, -0.4633],\n",
      "        [ 0.2495, -0.3601,  0.0563,  0.6795, -0.0025, -0.7777, -0.5845,  0.0661,\n",
      "          0.1195, -0.4718],\n",
      "        [ 0.2814, -0.3382,  0.0272,  0.7245,  0.0389, -0.7296, -0.5493,  0.0232,\n",
      "          0.0646, -0.4749]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initialize and test forward pass\n",
    "model = HybridDensityQNN(num_sub_unitaries=2)\n",
    "output = model(images)\n",
    "\n",
    "print(f\"Input shape: {images.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Mixing coefficients α: {torch.softmax(model.alpha, dim=0).detach()}\")\n",
    "print(f\"\\nOutput logits:\\n{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Analysis\n",
    "\n",
    "Let's analyze the model's output and performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Analysis:\n",
      "--------------------------------------------------\n",
      "Image 1:\n",
      "True class: plane\n",
      "Predicted: cat (Confidence: 20.15%)\n",
      "Top 3 predictions:\n",
      "  cat: 20.15%\n",
      "  plane: 12.97%\n",
      "  ship: 11.39%\n",
      "\n",
      "Image 2:\n",
      "True class: horse\n",
      "Predicted: cat (Confidence: 20.08%)\n",
      "Top 3 predictions:\n",
      "  cat: 20.08%\n",
      "  plane: 13.02%\n",
      "  ship: 10.95%\n",
      "\n",
      "Image 3:\n",
      "True class: dog\n",
      "Predicted: cat (Confidence: 20.04%)\n",
      "Top 3 predictions:\n",
      "  cat: 20.04%\n",
      "  plane: 13.04%\n",
      "  ship: 11.45%\n",
      "\n",
      "Image 4:\n",
      "True class: horse\n",
      "Predicted: cat (Confidence: 20.76%)\n",
      "Top 3 predictions:\n",
      "  cat: 20.76%\n",
      "  plane: 13.33%\n",
      "  ship: 10.73%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Analyze Predictions\n",
    "probabilities = torch.softmax(output, dim=1)\n",
    "predictions = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "# CIFAR-10 classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(\"Prediction Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(len(predictions)):\n",
    "    true_class = classes[labels[i]]\n",
    "    pred_class = classes[predictions[i]]\n",
    "    confidence = probabilities[i][predictions[i]] * 100\n",
    "    \n",
    "    print(f\"Image {i + 1}:\")\n",
    "    print(f\"True class: {true_class}\")\n",
    "    print(f\"Predicted: {pred_class} (Confidence: {confidence:.2f}%)\")\n",
    "    print(f\"Top 3 predictions:\")\n",
    "    \n",
    "    # Get top 3 predictions\n",
    "    top3_prob, top3_idx = torch.topk(probabilities[i], 3)\n",
    "    for j in range(3):\n",
    "        print(f\"  {classes[top3_idx[j]]}: {top3_prob[j]*100:.2f}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum Layer Analysis:\n",
      "--------------------------------------------------\n",
      "Sub-unitary mixing coefficients:\n",
      "α_1: 0.5000\n",
      "α_2: 0.5000\n",
      "\n",
      "Quantum circuit outputs for first image:\n",
      "Circuit 1 output: tensor([ 0.6200, -1.0000, -1.0000,  0.4400])\n",
      "Circuit 2 output: tensor([-0.6600, -0.8400, -0.6200, -0.6200])\n",
      "\n",
      "Weighted sum: tensor([-0.0200, -0.9200, -0.8100, -0.0900], grad_fn=<AddBackward0>)\n",
      "Quantum circuit outputs for first image:\n",
      "Circuit 1 output: tensor([ 0.6200, -1.0000, -1.0000,  0.4400])\n",
      "Circuit 2 output: tensor([-0.6600, -0.8400, -0.6200, -0.6200])\n",
      "\n",
      "Weighted sum: tensor([-0.0200, -0.9200, -0.8100, -0.0900], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 2. Analyze Quantum Layer Behavior\n",
    "print(\"Quantum Layer Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Analyze mixing coefficients\n",
    "alpha_norm = torch.softmax(model.alpha, dim=0)\n",
    "print(\"Sub-unitary mixing coefficients:\")\n",
    "for k in range(model.K):\n",
    "    print(f\"α_{k + 1}: {alpha_norm[k]:.4f}\")\n",
    "print()\n",
    "\n",
    "# Get quantum outputs for first image\n",
    "with torch.no_grad():\n",
    "    # Extract features\n",
    "    x = images[0:1]  # Add batch dimension\n",
    "    x = model.pool(torch.relu(model.conv1(x)))\n",
    "    x = model.pool(torch.relu(model.conv2(x)))\n",
    "    x = x.view(-1, 16 * 5 * 5)\n",
    "    angles = torch.tanh(model.fc1(x)) * 3.1415\n",
    "    \n",
    "    # Get outputs from each quantum layer\n",
    "    quantum_outputs = [layer(angles[0]) for layer in model.quantum_layers]\n",
    "    \n",
    "print(\"Quantum circuit outputs for first image:\")\n",
    "for k in range(model.K):\n",
    "    print(f\"Circuit {k + 1} output: {quantum_outputs[k]}\")\n",
    "print(f\"\\nWeighted sum: {sum(alpha_norm[k] * quantum_outputs[k] for k in range(model.K))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m features_np = features.numpy()\n\u001b[32m     24\u001b[39m quantum_np = quantum_outputs.numpy()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m labels_np = labels.numpy()  \u001b[38;5;66;03m# CIFAR labels are already numeric 0-9\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Plot\u001b[39;00m\n\u001b[32m     28\u001b[39m fig, (ax1, ax2) = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m14\u001b[39m, \u001b[32m5\u001b[39m))\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "# 3. Visualize Feature Spaces\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Extract pre-quantum features\n",
    "    x = model.pool(torch.relu(model.conv1(images)))\n",
    "    x = model.pool(torch.relu(model.conv2(x)))\n",
    "    x = x.view(-1, 16 * 5 * 5)\n",
    "    features = model.fc1(x)\n",
    "    \n",
    "    # Get quantum outputs\n",
    "    x = torch.tanh(features)\n",
    "    alpha_norm = torch.softmax(model.alpha, dim=0)\n",
    "    \n",
    "    quantum_outputs = []\n",
    "    for i in range(len(x)):\n",
    "        circuit_outputs = [layer(x[i:i+1]) for layer in model.quantum_layers]\n",
    "        quantum_out = sum(alpha_norm[k] * circuit_outputs[k] for k in range(model.K))\n",
    "        quantum_outputs.append(quantum_out.squeeze())\n",
    "    quantum_outputs = torch.stack(quantum_outputs)\n",
    "\n",
    "# Convert to numpy and get numeric labels\n",
    "features_np = features.numpy()\n",
    "quantum_np = quantum_outputs.numpy()\n",
    "labels_np = labels.numpy()  # CIFAR labels are already numeric 0-9\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "scatter1 = ax1.scatter(features_np[:, 0], features_np[:, 1], c=labels_np, cmap='tab10', s=100)\n",
    "ax1.set_title('Pre-Quantum Feature Space', fontsize=14)\n",
    "ax1.set_xlabel('Feature Dim 1')\n",
    "ax1.set_ylabel('Feature Dim 2')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=ax1, label='Class')\n",
    "\n",
    "scatter2 = ax2.scatter(quantum_np[:, 0], quantum_np[:, 1], c=labels_np, cmap='tab10', s=100)\n",
    "ax2.set_title('Quantum Feature Space', fontsize=14)\n",
    "ax2.set_xlabel('Qubit 0 ⟨Z⟩')\n",
    "ax2.set_ylabel('Qubit 1 ⟨Z⟩')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=ax2, label='Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Pre-Quantum range: [{features.min():.3f}, {features.max():.3f}]\")\n",
    "print(f\"Quantum range: [{quantum_outputs.min():.3f}, {quantum_outputs.max():.3f}]\")\n",
    "print(f\"\\nPre-Quantum mean±std: {features.mean():.3f}±{features.std():.3f}\")\n",
    "print(f\"Quantum mean±std: {quantum_outputs.mean():.3f}±{quantum_outputs.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
